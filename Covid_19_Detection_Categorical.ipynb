{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravitejalakkoju/covid-19-prediction-fyp/blob/main/Covid_19_Detection_Categorical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH1zXDbK9LHT"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmkJ8wGf9UQH"
      },
      "source": [
        "import opendatasets as od\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torchvision.datasets import ImageFolder\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jthFVSs9Yp_"
      },
      "source": [
        "kaggle_dataset_url=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT8ZtNc-9bDe"
      },
      "source": [
        "github_dataset_url=\"https://github.com/education454/datasets.git\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9olglhv9fOE",
        "outputId": "22621ed7-f164-42ed-aebf-5bf6334fbd05"
      },
      "source": [
        "od.download(kaggle_dataset_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2WvVTHo9wRN"
      },
      "source": [
        "!git clone https://github.com/education454/datasets.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6wC5Htd90El"
      },
      "source": [
        "kaggle_dir='./chest-xray-pneumonia/chest_xray'\n",
        "ktrain_dir = os.path.join(kaggle_dir, 'train')\n",
        "ktest_dir = os.path.join(kaggle_dir, 'test')\n",
        "kval_dir = os.path.join(kaggle_dir, 'val')\n",
        "train_pneumonia_dir = os.path.join(ktrain_dir, 'PNEUMONIA')\n",
        "train_normal_dir = os.path.join(ktrain_dir, 'NORMAL')\n",
        "test_pneumonia_dir = os.path.join(ktest_dir, 'PNEUMONIA')\n",
        "test_normal_dir = os.path.join(ktest_dir, 'NORMAL')\n",
        "val_pneumonia_dir = os.path.join(kval_dir, 'PNEUMONIA')\n",
        "val_normal_dir = os.path.join(kval_dir, 'NORMAL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CmXT6Na-wkG"
      },
      "source": [
        "github_dir = './datasets/Data'\n",
        "gtrain_dir = os.path.join(github_dir, 'train')\n",
        "gtest_dir = os.path.join(github_dir, 'test')\n",
        "train_covid_dir = os.path.join(gtrain_dir, 'COVID19')\n",
        "test_covid_dir = os.path.join(gtest_dir, 'COVID19')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riTUtPSy_WhP"
      },
      "source": [
        "ktrain_dir = pathlib.Path(ktrain_dir)\n",
        "ktest_dir = pathlib.Path(ktest_dir)\n",
        "kval_dir = pathlib.Path(kval_dir)\n",
        "print(\"TOTAL: %3d, PNEUMONIA: %3d, NORMAL: %3d\" % (len(list(ktrain_dir.glob('*/*'))), len(list(ktrain_dir.glob('*PNEUMONIA/*'))), len(list(ktrain_dir.glob('*NORMAL/*')))))\n",
        "print(\"TOTAL: %3d, PNEUMONIA: %3d, NORMAL: %3d\" % (len(list(ktest_dir.glob('*/*'))), len(list(ktest_dir.glob('*PNEUMONIA/*'))), len(list(ktest_dir.glob('*NORMAL/*')))))\n",
        "print(\"TOTAL: %3d, PNEUMONIA: %3d, NORMAL: %3d\" % (len(list(kval_dir.glob('*/*'))), len(list(kval_dir.glob('*PNEUMONIA/*'))), len(list(kval_dir.glob('*NORMAL/*')))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-fyRRV_fZU"
      },
      "source": [
        "gtrain_dir = pathlib.Path(gtrain_dir)\n",
        "gtest_dir = pathlib.Path(gtest_dir)\n",
        "print(\"TOTAL: %3d, COVID19: %3d, NORMAL: %3d\" % (len(list(gtrain_dir.glob('*/*'))), len(list(gtrain_dir.glob('*COVID19/*'))), len(list(gtrain_dir.glob('*NORMAL/*')))))\n",
        "print(\"TOTAL: %3d, COVID19: %3d, NORMAL: %3d\" % (len(list(gtest_dir.glob('*/*'))), len(list(gtest_dir.glob('*COVID19/*'))), len(list(gtest_dir.glob('*NORMAL/*')))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfJB-wpSE-XN"
      },
      "source": [
        "train_pneumonia_names = os.listdir(train_pneumonia_dir)\n",
        "print(train_pneumonia_names[:10])\n",
        "\n",
        "train_covid_names = os.listdir(train_covid_dir)\n",
        "print(train_covid_names[:10])\n",
        "\n",
        "train_normal_names = os.listdir(train_normal_dir)\n",
        "print(train_normal_names[:10])\n",
        "\n",
        "test_pneumonia_names = os.listdir(test_pneumonia_dir)\n",
        "print(train_pneumonia_names[:10])\n",
        "\n",
        "test_covid_names = os.listdir(test_covid_dir)\n",
        "print(train_covid_names[:10])\n",
        "\n",
        "test_normal_names = os.listdir(test_normal_dir)\n",
        "print(train_normal_names[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-PvAhuxBJkx"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(12,12)\n",
        "\n",
        "next_covid_pic = [os.path.join(train_covid_dir, fname)for fname in train_covid_names[0:4]]\n",
        "next_pneumonia_pic = [os.path.join(train_pneumonia_dir, fname)for fname in train_pneumonia_names[0:4]]\n",
        "next_normal_pic = [os.path.join(train_normal_dir, fname)for fname in train_normal_names[0:4]]\n",
        "\n",
        "print(next_covid_pic)\n",
        "print(next_pneumonia_pic)\n",
        "print(next_normal_pic)\n",
        "\n",
        "for i , img_path in enumerate(next_covid_pic + next_pneumonia_pic + next_normal_pic) : \n",
        "  data = img_path.split('/', 5)[5]\n",
        "  sp = plt.subplot(nrows, ncols,i+1)\n",
        "  sp.axis('Off')\n",
        "  img = mpimg.imread(img_path)\n",
        "  sp.set_title(data, fontsize = 10)\n",
        "  plt.imshow(img, cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBpgblSjb3lb"
      },
      "source": [
        "categorical_test_df = pd.DataFrame(columns =['class', 'o_directory', 'i_directory'])\n",
        "categorical_train_df = pd.DataFrame(columns =['class', 'o_directory', 'i_directory'])\n",
        "for dirpath, dirnames, filenames in os.walk(train_normal_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"NORMAL\", ('NORMAL/' + filename), (train_normal_dir + '/' +filename) ] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index()\n",
        "        i += 1\n",
        "        if i==545:\n",
        "            break\n",
        "for dirpath, dirnames, filenames in os.walk(test_normal_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"NORMAL\", ('NORMAL/' + filename), (test_normal_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index() \n",
        "        i += 1\n",
        "        if i==80:\n",
        "            break \n",
        "for dirpath, dirnames, filenames in os.walk(train_covid_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"COVID19\", ('COVID19/' + filename), (train_covid_dir + '/' +filename)] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index() \n",
        "for dirpath, dirnames, filenames in os.walk(test_covid_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"COVID19\", ('COVID19/' + filename), (test_covid_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index()\n",
        "        i += 1\n",
        "        if i==80:\n",
        "            break \n",
        "for dirpath, dirnames, filenames in os.walk(train_pneumonia_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"PNEUMONIA\", ('PNEUMONIA/' + filename), (train_pneumonia_dir + '/' +filename)] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index() \n",
        "        i += 1\n",
        "        if i==545:\n",
        "            break\n",
        "for dirpath, dirnames, filenames in os.walk(test_pneumonia_dir):\n",
        "    i = 0;\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"PNEUMONIA\", ('PNEUMONIA/' + filename), (test_pneumonia_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index()\n",
        "        i += 1\n",
        "        if i==80:\n",
        "            break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNSsnXfZLhGk"
      },
      "source": [
        "categorical_test_df = pd.DataFrame(columns =['class', 'o_directory', 'i_directory'])\n",
        "categorical_train_df = pd.DataFrame(columns =['class', 'o_directory', 'i_directory'])\n",
        "for dirpath, dirnames, filenames in os.walk(train_normal_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"NORMAL\", ('NORMAL/' + filename), (train_normal_dir + '/' +filename) ] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index()\n",
        "for dirpath, dirnames, filenames in os.walk(test_normal_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"NORMAL\", ('NORMAL/' + filename), (test_normal_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index()  \n",
        "for dirpath, dirnames, filenames in os.walk(val_normal_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"NORMAL\", ('NORMAL/' + filename), (val_normal_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index()  \n",
        "for dirpath, dirnames, filenames in os.walk(train_covid_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"COVID19\", ('COVID19/' + filename), (train_covid_dir + '/' +filename)] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index() \n",
        "for dirpath, dirnames, filenames in os.walk(test_covid_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"COVID19\", ('COVID19/' + filename), (test_covid_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index() \n",
        "for dirpath, dirnames, filenames in os.walk(train_pneumonia_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_train_df.loc[-1] = [\"PNEUMONIA\", ('PNEUMONIA/' + filename), (train_pneumonia_dir + '/' +filename)] \n",
        "        categorical_train_df.index = categorical_train_df.index + 1 \n",
        "        categorical_train_df = categorical_train_df.sort_index() \n",
        "for dirpath, dirnames, filenames in os.walk(test_pneumonia_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"PNEUMONIA\", ('PNEUMONIA/' + filename), (test_pneumonia_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index() \n",
        "for dirpath, dirnames, filenames in os.walk(val_pneumonia_dir):\n",
        "    for filename in filenames:\n",
        "        categorical_test_df.loc[-1] = [\"PNEUMONIA\", ('PNEUMONIA/' + filename), (val_pneumonia_dir + '/' +filename)] \n",
        "        categorical_test_df.index = categorical_test_df.index + 1 \n",
        "        categorical_test_df = categorical_test_df.sort_index() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dSt3-hePhoS"
      },
      "source": [
        "categorical_train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHUywuY4Yrtq"
      },
      "source": [
        "categorical_test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1iQIr7IP794"
      },
      "source": [
        "def copy_images_categorical(df, directory):\n",
        "    \n",
        "    # input and output directory\n",
        "    output_path = \"CategoricalDataSet/\" + directory\n",
        "\n",
        "    # remove all files from previous fold\n",
        "    if os.path.exists(output_path):\n",
        "        shutil.rmtree(output_path)\n",
        "\n",
        "    # create folder for files from this fold\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    # create subfolders for each class\n",
        "    classs=['NORMAL','COVID19','PNEUMONIA']\n",
        "    for c in classs:\n",
        "        if not os.path.exists(output_path + '/' + c):\n",
        "            os.makedirs(output_path + '/' + c)\n",
        "        \n",
        "    # copy files\n",
        "    for i, row in df.iterrows():\n",
        "        path_from = row['i_directory']\n",
        "        path_to = \"{}/{}\".format(output_path, (row['i_directory'].split('/')[-2]  + '/' + row['i_directory'].split('/')[-1]))\n",
        "        shutil.copy(path_from, path_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE8_rxzETNto"
      },
      "source": [
        "copy_images_categorical(categorical_test_df, 'test')\n",
        "copy_images_categorical(categorical_train_df, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOdd-889Z4AJ"
      },
      "source": [
        "print(len(os.listdir('./CategoricalDataSet/test/NORMAL')))\n",
        "print(len(os.listdir('./CategoricalDataSet/test/COVID19')))\n",
        "print(len(os.listdir('./CategoricalDataSet/test/PNEUMONIA')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkGBGNd8aFS2"
      },
      "source": [
        "print(len(os.listdir('./CategoricalDataSet/train/NORMAL')))\n",
        "print(len(os.listdir('./CategoricalDataSet/train/COVID19')))\n",
        "print(len(os.listdir('./CategoricalDataSet/train/PNEUMONIA')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srQZiIk3aSAZ"
      },
      "source": [
        "train_dir = './CategoricalDataSet/train'\n",
        "test_dir = './CategoricalDataSet/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOvdyBgnaVCa"
      },
      "source": [
        "train_dir = pathlib.Path(train_dir)\n",
        "image_count = len(list(train_dir.glob('*/*')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtrU86SaXdC"
      },
      "source": [
        "test_dir = pathlib.Path(test_dir)\n",
        "image_count = len(list(test_dir.glob('*/*')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJJTNn7a0O7"
      },
      "source": [
        "train_dir = pathlib.Path(train_dir)\n",
        "test_dir = pathlib.Path(test_dir)\n",
        "print(\"TOTAL: %3d, PNEUMONIA: %3d, COVID19: %3d, NORMAL: %3d\" % (len(list(train_dir.glob('*/*'))), len(list(train_dir.glob('*PNEUMONIA/*'))), len(list(train_dir.glob('*COVID19/*'))), len(list(train_dir.glob('*NORMAL/*')))))\n",
        "print(\"TOTAL: %3d, PNEUMONIA: %3d, COVID19: %3d, NORMAL: %3d\" % (len(list(test_dir.glob('*/*'))), len(list(test_dir.glob('*PNEUMONIA/*'))), len(list(test_dir.glob('*COVID19/*'))), len(list(test_dir.glob('*NORMAL/*')))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr6Rqd6vlIzB"
      },
      "source": [
        "image_size = (512, 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoJ4HbW9bjxe"
      },
      "source": [
        "train_data_gen = ImageDataGenerator(rescale  = 1./255, \n",
        "                                    validation_split=0.1)\n",
        "\n",
        "#                                     horizontal_flip = True,\n",
        "#                                     zoom_range = 0.2,\n",
        "#                                     rotation_range = 0,\n",
        "#                                     fill_mode='nearest'\n",
        "\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale  = 1./255)\n",
        "\n",
        "\n",
        "train_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                     target_size = image_size,\n",
        "                                                     subset = 'training', \n",
        "                                                     batch_size = 32,\n",
        "                                                     class_mode = 'categorical')\n",
        "\n",
        "val_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                     target_size = image_size,\n",
        "                                                     subset = 'validation', \n",
        "                                                     batch_size = 32,\n",
        "                                                     class_mode = 'categorical')\n",
        "\n",
        "test_generator = test_data_gen.flow_from_directory(test_dir,\n",
        "                                                     target_size = image_size,\n",
        "                                                     batch_size = 32,\n",
        "                                                     class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTgqYlPFdYqr"
      },
      "source": [
        "class_names = os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_A6TQX4DfzA"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "for i in range(15):\n",
        "  pyplot.subplot(4, 4, i + 1)\n",
        "  img, labels = train_generator.next()\n",
        "  image = img[0]\n",
        "  pyplot.xticks([])\n",
        "  pyplot.yticks([])\n",
        "  pyplot.subplots_adjust(top=1, left=0.5)\n",
        "  pyplot.imshow(image[:, :, 0], cmap='gray')\n",
        "  pyplot.title(class_names[labels[i].argmax()])\n",
        "  pyplot.gcf().set_size_inches(20, 10)\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcYkly-WeUeu"
      },
      "source": [
        "Model Formulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwZIEDTHeWgw"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVGu402leeOk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\", input_shape=(512,512,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm2ACwllefby"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV9Oo1K5ejtA"
      },
      "source": [
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxQQ83LtelEU"
      },
      "source": [
        "model.compile(Adam(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy', keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJeG4T-5Y74M"
      },
      "source": [
        "model_fit = model.fit(train_generator, epochs=2, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC290Fw5XFfi"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnEagOIYFi8B"
      },
      "source": [
        "test_loss, test_acc, test_auc, test_precision, test_recall = model.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {}, test_auc: {}, test_precision: {}, test_precision: {}'.format(test_acc, test_loss, test_auc, test_precision, test_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vciXuOKxTa1"
      },
      "source": [
        "f1_score(0.8163001537322998, 0.8163001537322998)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_yd3Be5XQyX"
      },
      "source": [
        "Y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLsHYaD9FwfU"
      },
      "source": [
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QToXjMK9iCKf"
      },
      "source": [
        "target_names = []\n",
        "\n",
        "for key in train_generator.class_indices:\n",
        "\n",
        "    target_names.append(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-Fs4oXh7w-"
      },
      "source": [
        "print('Classification Report')\n",
        "\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM7orh_nphuZ"
      },
      "source": [
        "def f1_score(test_precision, test_recall): \n",
        "  return ((2* test_precision * test_recall) / (test_precision + test_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqqhC_wzidFF"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwvDUgnOid24"
      },
      "source": [
        "conv_base = DenseNet121(weights='imagenet',\n",
        " include_top=False,\n",
        " input_shape=(512, 512, 3))\n",
        "conv_base.trainable = False\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.Adam(lr=0.001),\n",
        " metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcgW42fNiiJt"
      },
      "source": [
        "conv_base = ResNet50(weights='imagenet',\n",
        " include_top=False,\n",
        " input_shape=(512, 512, 3))\n",
        "conv_base.trainable = False\n",
        "model2 = models.Sequential()\n",
        "model2.add(conv_base)\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(256, activation='relu'))\n",
        "model2.add(layers.Dense(3, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.Adam(lr=0.001),\n",
        " metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkqpJ6MEi4Rl"
      },
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        " include_top=False,\n",
        " input_shape=(512, 512, 3))\n",
        "conv_base.trainable = False\n",
        "model3 = models.Sequential()\n",
        "model3.add(conv_base)\n",
        "model3.add(layers.Flatten())\n",
        "model3.add(layers.Dense(256, activation='relu'))\n",
        "model3.add(layers.Dense(3, activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.Adam(lr=0.001),\n",
        " metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS6MSs6xjB58"
      },
      "source": [
        "conv_base = InceptionV3(weights='imagenet',\n",
        " include_top=False,\n",
        " input_shape=(512, 512, 3))\n",
        "conv_base.trainable = False\n",
        "model4 = models.Sequential()\n",
        "model4.add(conv_base)\n",
        "model4.add(layers.Flatten())\n",
        "model4.add(layers.Dense(256, activation='relu'))\n",
        "model4.add(layers.Dense(3, activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.Adam(lr=0.001),\n",
        " metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJaBPh10uXEC"
      },
      "source": [
        "from keras.applications import InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUI5zHh4uWrV"
      },
      "source": [
        "conv_base = InceptionV3(weights='imagenet',\n",
        " include_top=False,\n",
        " input_shape=(512, 512, 3))\n",
        "conv_base.trainable = False\n",
        "model5 = models.Sequential()\n",
        "model5.add(conv_base)\n",
        "model5.add(layers.Flatten())\n",
        "model5.add(layers.Dense(256, activation='relu'))\n",
        "model5.add(layers.Dense(3, activation='softmax'))\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.Adam(lr=0.001),\n",
        " metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU3-XtjajO_F"
      },
      "source": [
        "model_fit = model.fit(train_generator, epochs=2, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPP6AbCQpXLE"
      },
      "source": [
        "test_loss, test_acc, test_precision, test_recall, test_auc = model.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc, test_loss, test_precision, test_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwnUOUrUjR6F"
      },
      "source": [
        "model_fit2 = model2.fit(train_generator, epochs=3, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlZxR28npX9G"
      },
      "source": [
        "test_loss2, test_acc2, test_precision2, test_recall2, test_auc2 = model2.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc2, test_loss2, test_precision2, test_recall2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYNVjJuosgT7"
      },
      "source": [
        "print(f1_score(test_precision2, test_recall2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHM9yK3mjSkn"
      },
      "source": [
        "model_fit3 = model3.fit(train_generator, epochs=3, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wCK2wt2pY0B"
      },
      "source": [
        "test_loss3, test_acc3, test_precision3, test_recall3, test_auc3 = model3.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc3, test_loss3, test_precision3, test_recall3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ZKsGscsir8"
      },
      "source": [
        "print(f1_score(test_precision3, test_recall3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM-i7trojS1p"
      },
      "source": [
        "model_fit4 = model4.fit(train_generator, epochs=3, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbH6-vb1pZMp"
      },
      "source": [
        "test_loss4, test_acc4, test_precision4, test_recall4, test_auc4 = model4.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc4, test_loss4, test_precision4, test_recall4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxlv88ecslEN"
      },
      "source": [
        "print(f1_score(test_precision4, test_recall4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur4He1ngue9O"
      },
      "source": [
        "model_fit5 = model5.fit(train_generator, epochs=3, validation_data=val_generator, batch_size=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWMbIItTue8U"
      },
      "source": [
        "test_loss5, test_acc5, test_precision5, test_recall5, test_auc5 = model5.evaluate(test_generator)\n",
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc5, test_loss5, test_precision5, test_recall5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK8HEftSz_NE"
      },
      "source": [
        "print('test_acc : {} test_loss : {} test_precision: {}, test_recall: {}'.format(test_acc5, test_loss5, test_precision5, test_recall5))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLOECYl50CTI"
      },
      "source": [
        "print(test_auc5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbuNehanuljB"
      },
      "source": [
        "print(f1_score(test_precision5, test_recall5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77vsQJ515dke"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Ob2YPqule9"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    This function prints and plots the confusion matrix.\n",
        "\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.colorbar()\n",
        "\n",
        "\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        cm = np.around(cm, decimals=2)\n",
        "\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        print(\"Normalized confusion matrix\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "\n",
        "        plt.text(j, i, cm[i, j],\n",
        "\n",
        "                 horizontalalignment=\"center\",\n",
        "\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlPsjncC46Th"
      },
      "source": [
        "target_names = []\n",
        "\n",
        "for key in train_generator.class_indices:\n",
        "\n",
        "    target_names.append(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIa5pt149dP"
      },
      "source": [
        "Y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fERHgGFG5X1z"
      },
      "source": [
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "\n",
        "print(cm)\n",
        "plot_confusion_matrix(cm, target_names, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6S4_XC55X0z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "langs = ['Covid-19', 'Normal', 'Pneumonia']\n",
        "students = [len(list(train_dir.glob('*COVID19/*'))), len(list(train_dir.glob('*NORMAL/*'))), len(list(train_dir.glob('*PNEUMONIA/*')))]\n",
        "ax.bar(langs,students)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLDxYCsw8zcf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "langs = ['Covid-19', 'Normal', 'Pneumonia']\n",
        "students = [len(list(test_dir.glob('*COVID19/*'))), len(list(test_dir.glob('*NORMAL/*'))), len(list(test_dir.glob('*PNEUMONIA/*')))]\n",
        "ax.bar(langs,students)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}